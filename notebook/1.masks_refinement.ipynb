{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory of the current notebook\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from process_masks import (\n",
    "    refine_cloud_mask,\n",
    "    refine_shadow_mask,\n",
    "    generate_seasonal_backgrounds\n",
    ")\n",
    "\n",
    "from scripting import (\n",
    "    print_map,\n",
    "    get_season_id,\n",
    "    load_s2,\n",
    "    preprocess,\n",
    "    set_bands,\n",
    "    drop_aux_bands,\n",
    "    get_scl_mask,\n",
    ")\n",
    "\n",
    "import rioxarray\n",
    "import dask\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import re\n",
    "import datetime\n",
    "import rasterio\n",
    "from glob import glob\n",
    "from datetime import date\n",
    "\n",
    "def read_yaml(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as yaml_file: return yaml.safe_load(yaml_file)\n",
    "    \n",
    "def fix_paths_for_nb(input_dict, old_substring = \"/home/hrlcuser/media\", new_substring = \"/media/datapart/lucazanolo\"):\n",
    "    return {\n",
    "        key: (value.replace(old_substring, new_substring) if isinstance(value, str) else value)\n",
    "        for key, value in input_dict.items()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = fix_paths_for_nb(read_yaml(\"/home/lucazanolo/luca-zanolo/scripts/config_files/1.masks_refinement.yaml\"))\n",
    "\n",
    "resolutions = parameters[\"resolutions\"]\n",
    "\n",
    "dask_graph_path = f\"{parameters['output_path']}/dask_graph/\"\n",
    "bg_output_path = f\"{parameters['output_path']}/backgrounds\"\n",
    "cloud_masks_path = f\"{parameters['output_path']}/cloud_masks\"\n",
    "shadow_masks_path = f\"{parameters['output_path']}/shadow_masks\"\n",
    "\n",
    "os.makedirs(cloud_masks_path, exist_ok=True)\n",
    "os.makedirs(bg_output_path, exist_ok=True)\n",
    "os.makedirs(dask_graph_path, exist_ok=True)\n",
    "os.makedirs(shadow_masks_path, exist_ok=True)\n",
    "\n",
    "SAVE_DATA = True\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(\n",
    "        os.cpu_count() or 2\n",
    "    ),\n",
    "    \n",
    ") as client:\n",
    "\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "    # Load datasets and set the band names\n",
    "    dss = {res: load_s2(parameters[\"input_path\"], \n",
    "                        group=res, \n",
    "                        preprocess=preprocess, \n",
    "                        tile=parameters[\"tile_id\"], \n",
    "                        sensor=parameters[\"sensor\"], \n",
    "                        year=parameters[\"year\"]) for res in resolutions}\n",
    "    \n",
    "    dss = {res: set_bands(dss[res], only_bands=False) for res in resolutions}\n",
    "    scls = {res : dss[res].sel(band='SCL') for res in resolutions if res in [\"20m\", \"60m\"]} # Isolating SCLs band\n",
    "    dss, band_names = drop_aux_bands(**dss) # Dropping auxiliary bands\n",
    "    \n",
    "    if \"10m\" in resolutions:\n",
    "        print(f\"Estimating SCL mask for 10m resolution\")\n",
    "        ref = \"20m\" if \"20m\" in resolutions else \"60m\"\n",
    "        scls[\"10m\"] = scls[ref].interp(\n",
    "            \n",
    "            dict(x=dss[\"10m\"].coords[\"x\"], y=dss[\"10m\"].coords[\"y\"]),\n",
    "            method=\"nearest\",\n",
    "            kwargs=dict(fill_value=\"extrapolate\"),\n",
    "        )        \n",
    "\n",
    "    print(f\"Start retrieving masks from SCL band. Masks Requested: {parameters['mask_definitions']}\")\n",
    "\n",
    "    scl_masks = xr.concat([\n",
    "        xr.concat(\n",
    "            [\n",
    "                get_scl_mask(scls[resolutions[0]].sel(time=t), scl_values)\n",
    "                .expand_dims({\"mask_type\": [mask_type]})\n",
    "                .astype(bool)\n",
    "                for mask_type, scl_values in parameters[\"mask_definitions\"].items()\n",
    "            ], \n",
    "            dim=\"mask_type\"\n",
    "        )\n",
    "        for t in scls[resolutions[0]].time.values\n",
    "    ], dim=\"time\")\n",
    "    \n",
    "    scl_valid = scl_masks   \n",
    "\n",
    "    # Interpolating resolutions to 10m\n",
    "    dss_up: dict[str, xr.Dataset] = dict()\n",
    "\n",
    "    # Keep the 10m data (which includes B2 and B8) as is\n",
    "    dss_up[resolutions[0]] = dss[resolutions[0]]\n",
    "\n",
    "    # Interpolate only B11 from the 20m resolution dataset\n",
    "    if \"B11\" in dss[resolutions[1]].band:\n",
    "        dss_up[\"20m\"] = (\n",
    "            dss[\"20m\"]\n",
    "            .sel(band=\"B11\")\n",
    "            .interp(\n",
    "                dict(\n",
    "                    x=dss_up[resolutions[0]].coords[\"x\"],\n",
    "                    y=dss_up[resolutions[0]].coords[\"y\"],\n",
    "                ),\n",
    "                method=\"nearest\",\n",
    "                kwargs=dict(fill_value=\"extrapolate\"),\n",
    "            )\n",
    "            .astype(np.uint16)\n",
    "        )\n",
    "\n",
    "    # Concatenate the 10m data (B2, B8) with the interpolated B11\n",
    "    ds = xr.concat([dss_up[resolutions[0]], dss_up[\"20m\"]], dim=\"band\")\n",
    "    \n",
    "    ds.attrs[\"long_name\"] = band_names\n",
    "    ds = ds.assign(dict(masks=scl_valid))\n",
    "    #ds = ds.unify_chunks()\n",
    "    \n",
    "    print_map(scls, \"\\n\\n SCL ISOLATED BANDs\\n\")\n",
    "    print(f\"\\n\\n SCL MASKS (retrieved from interpolated DSS (-> DS))\\n\\n{scl_valid}\\n\\n\")\n",
    "    print_map(dss, \"\\n\\n DSS + SET_BANDS() + AUX_BANDS_DROP()\\n\")\n",
    "    print(f\"\\n\\n DSS + SET_BANDS() + AUX_BANDS_DROP() + INTERPOLATION to 10M\\n\\n{ds}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(\n",
    "        os.cpu_count() or 2\n",
    "    ),\n",
    "    \n",
    ") as client:\n",
    "\n",
    "\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "    backgrounds = generate_seasonal_backgrounds(ds, quantile = 0.25)\n",
    "    \n",
    "    print(f\"\\n\\nBackground:\\n\\n{backgrounds}\\n\\n\")\n",
    "    \n",
    "    for season, group in ds.groupby(\"season_id\"):\n",
    "        \n",
    "        # Background computation for current season\n",
    "        print(f\"[{season}] Processing season: {season}\")\n",
    "        background_path = f\"{bg_output_path}/background_{group.season_id.values[0]}.tif\" \n",
    "        background = backgrounds.sel(season_id = season)\n",
    "        \n",
    "        if not os.path.exists(background_path):\n",
    "            print(f\"[{season}] Start generating and saving background at {background_path}\")\n",
    "                        \n",
    "            background.rio.to_raster(\n",
    "                background_path,\n",
    "                compress=\"DEFLATE\",\n",
    "                num_threads=\"all_cpus\"\n",
    "            )\n",
    "            \n",
    "            print(f\"[{season}] Background saved\")\n",
    "\n",
    "        #background = rioxarray.open_rasterio(background_path).squeeze()\n",
    "        #background = background.compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine cloud and shadow masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(\n",
    "        os.cpu_count() or 2\n",
    "    ),\n",
    "    \n",
    ") as client:\n",
    "\n",
    "\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "\n",
    "    refined_cloud_masks = []\n",
    "    refined_shadow_masks = []\n",
    "\n",
    "    for season, group in ds.groupby(\"season_id\"):\n",
    "        \n",
    "        # Background computation for current season\n",
    "        print(f\"[{season}] Processing season: {season}\")\n",
    "        background_path = f\"{bg_output_path}/background_{group.season_id.values[0]}.tif\" \n",
    "        background = backgrounds.sel(season_id = season)\n",
    "        \n",
    "        if not os.path.exists(background_path):\n",
    "            print(f\"[{season}] Start generating and saving background at {background_path}\")\n",
    "                        \n",
    "            background.rio.to_raster(\n",
    "                background_path,\n",
    "                compress=\"DEFLATE\",\n",
    "                num_threads=\"all_cpus\"\n",
    "            )\n",
    "            \n",
    "            print(f\"[{season}] Background saved\")\n",
    "\n",
    "        background = rioxarray.open_rasterio(background_path).squeeze()\n",
    "        background = background.compute()\n",
    "        \n",
    "        # Masks refinement\n",
    "        \n",
    "        for time in group.time.values:\n",
    "            \n",
    "            print(f\"Generating and saving Sen2cor and refined cloud and shadow masks for {time}\")\n",
    "            c_group = group.sel(time = time)        \n",
    "                \n",
    "            ref_cloud_mask_path = f\"{cloud_masks_path}/{str(c_group.file_name.values)[:-4]}_cloudMediumMask.tif\"\n",
    "            ref_shadow_mask_path = f\"{shadow_masks_path}/{str(c_group.file_name.values)[:-4]}_shadowMask.tif\"            \n",
    "            \n",
    "            if not os.path.exists(ref_shadow_mask_path) or not os.path.exists(ref_cloud_mask_path):\n",
    "                c_group = c_group.load()\n",
    "                            \n",
    "            refined_cloud_mask = xr.apply_ufunc(\n",
    "                refine_cloud_mask,\n",
    "                group.data.sel(band=\"B2\"),                            # Blue band (B2) as input\n",
    "                group.masks.sel(mask_type=\"cloud\"),  \n",
    "                background,# Cloud mask\n",
    "                kwargs = {'cloud_coverage_threshold':parameters[\"cloud_coverage_threshold\"]},\n",
    "                input_core_dims=[['y', 'x'], ['y', 'x'], ['y', 'x']], \n",
    "                output_core_dims=[['y', 'x']],\n",
    "                vectorize=True,\n",
    "                dask=\"parallelized\",\n",
    "                output_dtypes=[np.uint8],\n",
    "                keep_attrs=True,\n",
    "                dask_gufunc_kwargs={'allow_rechunk': True}\n",
    "            )\n",
    "            del refined_cloud_mask.attrs['long_name']\n",
    "            \n",
    "            refined_shadow_mask = xr.apply_ufunc(\n",
    "                refine_shadow_mask,       \n",
    "                group.data.sel(band=\"B2\"),             # Blue band (B2)\n",
    "                group.data.sel(band=\"B8\"),             # NIR band (B8)\n",
    "                group.data.sel(band=\"B11\"),            # SWIR band (B11)\n",
    "                refined_cloud_mask,    # Cloud mask\n",
    "                group.masks.sel(mask_type=\"shadow\"),   # Shadow mask\n",
    "                kwargs={\"cloud_coverage_threshold\"   : parameters[\"cloud_coverage_threshold\"],\n",
    "                        \"image_brightness_threshold\" : parameters[\"image_brightness_threshold\"]},\n",
    "                input_core_dims=[\n",
    "                    ['y', 'x'], ['y', 'x'], ['y', 'x'], ['y', 'x'], ['y', 'x']],\n",
    "                output_core_dims=[['y', 'x']],\n",
    "                vectorize=True,\n",
    "                dask=\"parallelized\",\n",
    "                output_dtypes=[np.uint8],\n",
    "                keep_attrs=True,\n",
    "                dask_gufunc_kwargs={'allow_rechunk': True}\n",
    "            )\n",
    "            del refined_shadow_mask.attrs['long_name']\n",
    "        \n",
    "            date = str(time)[:10]\n",
    "\n",
    "            if not os.path.exists(ref_cloud_mask_path):\n",
    "\n",
    "                refined_cloud_mask.rio.to_raster(\n",
    "                    ref_cloud_mask_path,\n",
    "                    compress=\"DEFLATE\",\n",
    "                    num_threads=\"all_cpus\"\n",
    "                )\n",
    "                print(f\"[{season}][{date}] Saved refined cloud mask at {ref_cloud_mask_path}\")\n",
    "                \n",
    "            else: print(f\"[{season}][{date}] Skipping. Already exists: {ref_cloud_mask_path}\")\n",
    "            \n",
    "            if not os.path.exists(ref_shadow_mask_path):\n",
    "            \n",
    "                refined_shadow_mask.rio.to_raster(\n",
    "                    ref_shadow_mask_path,\n",
    "                    compress=\"DEFLATE\",\n",
    "                    num_threads=\"all_cpus\"\n",
    "                )\n",
    "                print(f\"[{season}][{date}] Saved refined shadow mask at {ref_shadow_mask_path}\")\n",
    "            else: print(f\"[{season}][{date}] Skipping. Already exists: {ref_shadow_mask_path}\")\n",
    "            \n",
    "            refined_shadow_masks.append(refined_shadow_mask)\n",
    "            refined_cloud_masks.append(refined_cloud_mask)\n",
    "            \n",
    "            del c_group, refined_cloud_mask, refined_shadow_mask\n",
    "\n",
    "        del background\n",
    "\n",
    "    refined_cloud_masks = xr.concat(refined_cloud_masks, dim='time')\n",
    "    refined_shadow_masks = xr.concat(refined_shadow_masks, dim='time')\n",
    "\n",
    "    refined_masks = xr.Dataset({\n",
    "        \"refined_cloud_masks\" : refined_cloud_masks,\n",
    "        \"refined_shadow_masks\" : refined_shadow_masks\n",
    "    })\n",
    "\n",
    "    print(f\"\\n\\n REFINED MASKS \\n\\n{refined_masks}\\n\\n\")\n",
    "    print(f\"\\n\\n BACKGROUNDS \\n\\n{backgrounds}\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect background/refined masks - Generate reports\n",
    "\n",
    "Only the load dataset cell must be runned. The backgrounds and refined masks should be already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_refined_masks(ds_slice):\n",
    "    \n",
    "    cloud_masks = []\n",
    "    shadow_masks = []\n",
    "\n",
    "    print(f\"\\n\\nDataset slice \\n{ds_slice}\\n\")\n",
    "    print(ds_slice.masks.sel(mask_type = \"cloud\"))\n",
    "    cloud_path = f\"{cloud_masks_path}/{str(ds_slice.file_name.values)[:-4]}_cloudMediumMask.tif\" \n",
    "    shadow_path = f\"{shadow_masks_path}/{str(ds_slice.file_name.values)[:-4]}_shadowMask.tif\"\n",
    "\n",
    "    print(f\"Loading refined cloud mask: {cloud_path}\")\n",
    "    cloud_mask = xr.DataArray(\n",
    "        rioxarray.open_rasterio(cloud_path).squeeze().data,\n",
    "        dims=ds_slice.masks.sel(mask_type = \"cloud\").dims,\n",
    "        coords=ds_slice.masks.sel(mask_type = \"cloud\").coords,\n",
    "        attrs=ds_slice.masks.sel(mask_type = \"cloud\").attrs\n",
    "    )\n",
    "    \n",
    "    print(f\"Loading refined shadow mask: {shadow_path}\")\n",
    "    shadow_mask = xr.DataArray(\n",
    "        rioxarray.open_rasterio(shadow_path).squeeze().data,\n",
    "        dims=ds_slice.masks.sel(mask_type = \"shadow\").dims,\n",
    "        coords=ds_slice.masks.sel(mask_type = \"shadow\").coords,\n",
    "        attrs=ds_slice.masks.sel(mask_type = \"shadow\").attrs\n",
    "    )\n",
    "    cloud_masks.append(cloud_mask)\n",
    "    shadow_masks.append(shadow_mask)\n",
    "        \n",
    "    cloud_masks_da = xr.concat(cloud_masks, dim='time')\n",
    "    shadow_masks_da = xr.concat(shadow_masks, dim='time')\n",
    "\n",
    "    ds_slice = ds_slice.assign({\n",
    "        \"refined_cloud_masks\":cloud_masks_da.astype(bool),\n",
    "        \"refined_shadow_masks\":shadow_masks_da.astype(bool)\n",
    "    })\n",
    "    \n",
    "    return ds_slice\n",
    "\n",
    "def calculate_percentage(mask):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of pixels with a value of 1 in the mask.\n",
    "    \"\"\"\n",
    "    total_pixels = mask.size\n",
    "    cloud_shadow_pixels = np.sum(mask == 1)\n",
    "    return (cloud_shadow_pixels / total_pixels) * 100\n",
    "\n",
    "def create_report(image, background, s2c_cloud_mask, s2c_shadow_mask, s2c_cloud_mask_ref, s2c_shadow_mask_ref, output_path=\"report.png\"):\n",
    "    \"\"\"\n",
    "    Create a report of subplots for the provided arrays and save the image.\n",
    "    \"\"\"\n",
    "    # Calculate percentages for masks\n",
    "    cloud_percentage = calculate_percentage(s2c_cloud_mask)\n",
    "    shadow_percentage = calculate_percentage(s2c_shadow_mask)\n",
    "    cloud_ref_percentage = calculate_percentage(s2c_cloud_mask_ref)\n",
    "    shadow_ref_percentage = calculate_percentage(s2c_shadow_mask_ref)\n",
    "\n",
    "    # Create the figure and subplots\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(20, 30))\n",
    "\n",
    "    # Plot the RGB bands\n",
    "    axes[0, 0].imshow(np.clip(image.transpose(1,2,0) / 3000, 0, 1), cmap=\"jet\")\n",
    "    axes[0, 0].set_title(\"Blue Band\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    # Plot the background\n",
    "    axes[0, 1].imshow(background, cmap=\"jet\")\n",
    "    axes[0, 1].set_title(\"Background\")\n",
    "    axes[0, 1].axis(\"off\")\n",
    "\n",
    "    # Plot cloud mask\n",
    "    axes[1, 0].imshow(s2c_cloud_mask, cmap=\"gray\")\n",
    "    axes[1, 0].set_title(f\"Cloud Mask\\n{cloud_percentage:.2f}% Cloud Pixels\")\n",
    "    axes[1, 0].axis(\"off\")\n",
    "\n",
    "    # Plot cloud mask refined\n",
    "    axes[1, 1].imshow(s2c_cloud_mask_ref, cmap=\"gray\")\n",
    "    axes[1, 1].set_title(f\"Cloud Mask Ref\\n{cloud_ref_percentage:.2f}% Cloud Pixels\")\n",
    "    axes[1, 1].axis(\"off\")\n",
    "\n",
    "    # Plot shadow mask\n",
    "    axes[2, 0].imshow(s2c_shadow_mask, cmap=\"gray\")\n",
    "    axes[2, 0].set_title(f\"Shadow Mask\\n{shadow_percentage:.2f}% Shadow Pixels\")\n",
    "    axes[2, 0].axis(\"off\")\n",
    "    \n",
    "    # Plot shadow mask refined\n",
    "    axes[2, 1].imshow(s2c_shadow_mask_ref, cmap=\"gray\")\n",
    "    axes[2, 1].set_title(f\"Shadow Mask Ref\\n{shadow_ref_percentage:.2f}% Shadow Pixels\")\n",
    "    axes[2, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Report saved as {output_path}\")\n",
    "    \n",
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(\n",
    "        os.cpu_count() or 2\n",
    "    ),\n",
    "    \n",
    ") as client:\n",
    "\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "\n",
    "    tile_id = \"10UED\"\n",
    "    report_path = f\"/media/datapart/lucazanolo/S2_processed_masks/reports\"    \n",
    "    os.makedirs(report_path, exist_ok=True)\n",
    "    limit = 2\n",
    "    for time_idx, time in enumerate(ds.time.values):\n",
    "        \n",
    "        print(time)\n",
    "        continue\n",
    "        print(f\"Generating report for time index: {time_idx}\")\n",
    "        curr_report_path = f\"{report_path}/report_{tile_id}_{time_idx}.png\"\n",
    "        print(curr_report_path)\n",
    "        if not os.path.exists(curr_report_path):\n",
    "            \n",
    "            time = ds.time.values[time_idx]\n",
    "            season = get_season_id(ds.time.values[time_idx])\n",
    "            bg_path = f\"{bg_output_path}/background_{tile_id}{season}.tif\"\n",
    "            ds_test = ds.isel(time=time_idx)\n",
    "            ds_test = load_refined_masks(ds_test)\n",
    "            \n",
    "            rgb_image = ds_test.data.sel(band = [\"B2\",\"B3\",\"B4\"]).values\n",
    "            background = rioxarray.open_rasterio(bg_path).squeeze().values\n",
    "            s2c_cloud_mask = ds_test.masks.sel(mask_type = \"cloud\").values\n",
    "            s2c_shadow_mask = ds_test.masks.sel(mask_type = \"shadow\").values\n",
    "            s2c_cloud_mask_ref = ds_test.refined_cloud_masks.squeeze().values\n",
    "            s2c_shadow_mask_ref = ds_test.refined_shadow_masks.squeeze().values\n",
    "\n",
    "            create_report(rgb_image, background, s2c_cloud_mask, s2c_shadow_mask, s2c_cloud_mask_ref, s2c_shadow_mask_ref, curr_report_path)\n",
    "            break\n",
    "    \n",
    "    \"\"\"\n",
    "    print(rgb_image.shape)\n",
    "    print(background.shape)\n",
    "    print(s2c_cloud_mask.shape)\n",
    "    print(s2c_shadow_mask.shape)\n",
    "    print(s2c_cloud_mask_ref.shape)\n",
    "    print(s2c_shadow_mask_ref.shape)\n",
    "    \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "background_path = \"/media/datapart/lucazanolo/S2_processed_masks/backgrounds/background_18NWL2019_1.tif\"\n",
    "background = rioxarray.open_rasterio(background_path)\n",
    "background_2d1 = background.squeeze(drop=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "background_2d1.plot()\n",
    "plt.title(\"Background Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "background_path = \"/media/datapart/lucazanolo/S2_processed_masks/backgrounds/backgroundImage_18NWL2019_1.tif\"\n",
    "background = rioxarray.open_rasterio(background_path)\n",
    "background_2d2 = background.squeeze(drop=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "background_2d2.plot()\n",
    "plt.title(\"Background Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask_report(tile: str, date: datetime.date, output_path=\"report.png\"):\n",
    "    import numpy as np\n",
    "    tile = tile.upper()\n",
    "\n",
    "    base_old = \"/media/datapart/lucazanolo/S2_processed_masks_old\"\n",
    "    base_new = \"/media/datapart/lucazanolo/S2_processed_masks\"\n",
    "\n",
    "    def find_background(path):\n",
    "        season = (date.month % 12 + 3) // 3  # 1=Winter, ..., 4=Fall\n",
    "        pattern = f\"backgroundImage_{tile}{date.year}_{season}.tif\"\n",
    "        matches = glob(os.path.join(path, \"backgrounds\", pattern))\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    def find_sen2cor_cloud_mask():\n",
    "        folder = os.path.join(base_old, \"cloud_masks\")\n",
    "        pattern = re.compile(\n",
    "            rf\"MSIL2A_{date.strftime('%Y%m%d')}T\\d+_N\\d+_R\\d+_T{tile}_\\d+T\\d+_cloudMediumMask_Sen2Cor\\.tif$\"\n",
    "        )\n",
    "        for file in os.listdir(folder):\n",
    "            if pattern.match(file):\n",
    "                return os.path.join(folder, file)\n",
    "        return None\n",
    "\n",
    "    def find_sen2cor_shadow_mask():\n",
    "        folder = os.path.join(base_old, \"shadow_masks\")\n",
    "        pattern = re.compile(\n",
    "            rf\"MSIL2A_{date.strftime('%Y%m%d')}T\\d+_N\\d+_R\\d+_T{tile}_\\d+T\\d+_shadowMask_Sen2Cor\\.tif$\"\n",
    "        )\n",
    "        for file in os.listdir(folder):\n",
    "            if pattern.match(file):\n",
    "                return os.path.join(folder, file)\n",
    "        return None\n",
    "    \n",
    "    def find_refined_cloud_mask(base_path):\n",
    "        folder = os.path.join(base_path, \"cloud_masks\")\n",
    "        pattern = re.compile(\n",
    "            rf\"MSIL2A_{date.strftime('%Y%m%d')}T\\d+_N\\d+_R\\d+_T{tile}_\\d+T\\d+_cloudMediumMask\\.tif$\"\n",
    "        )\n",
    "        for file in os.listdir(folder):\n",
    "            if pattern.match(file):\n",
    "                return os.path.join(folder, file)\n",
    "        return None\n",
    "\n",
    "    def find_refined_shadow_mask(base_path):\n",
    "        folder = os.path.join(base_path, \"shadow_masks\")\n",
    "        pattern = re.compile(\n",
    "            rf\"MSIL2A_{date.strftime('%Y%m%d')}T\\d+_N\\d+_R\\d+_T{tile}_\\d+T\\d+_shadowMask\\.tif$\"\n",
    "        )\n",
    "        for file in os.listdir(folder):\n",
    "            if pattern.match(file):\n",
    "                return os.path.join(folder, file)\n",
    "        return None\n",
    "\n",
    "    # Find all required files\n",
    "    bg_old = find_background(base_old)\n",
    "    bg_new = find_background(base_new)\n",
    "\n",
    "    cloud_sen2cor = find_sen2cor_cloud_mask()\n",
    "    shadow_sen2cor = find_sen2cor_shadow_mask()\n",
    "\n",
    "    refined_old_cloud = find_refined_cloud_mask(base_old)\n",
    "    refined_old_shadow = find_refined_shadow_mask(base_old)\n",
    "    refined_new_cloud = find_refined_cloud_mask(base_new)\n",
    "    refined_new_shadow = find_refined_shadow_mask(base_new)\n",
    "\n",
    "    files = {\n",
    "        \"Existing Pipepline - Background\": bg_old,\n",
    "        \"Reimplemented Pipeline - Background\": bg_new,\n",
    "        \"Sen2Cor Cloud\": cloud_sen2cor,\n",
    "        \"Sen2Cor Shadow\": shadow_sen2cor,\n",
    "        \"Existing Pipeline - Refined Cloud\": refined_old_cloud,\n",
    "        \"Existing Pipeline - Refined Shadow\": refined_old_shadow,\n",
    "        \"Reimpl. Pipeline - Refined Cloud\": refined_new_cloud,\n",
    "        \"Reimpl. Pipeline - Refined Shadow\": refined_new_shadow,\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(10, 20))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for idx, (title, path) in enumerate(files.items()):\n",
    "        if path is None or not os.path.exists(path):\n",
    "            print(f\"{title} - Path: {path} does not exist!\")\n",
    "            continue\n",
    "        ax = axs[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read(1)\n",
    "            # Calcolo percentuale solo per le maschere\n",
    "            if \"Background\" not in title:\n",
    "                total_pixels = img.size\n",
    "                active_pixels = np.sum(img == 1)\n",
    "                percentage = (active_pixels / total_pixels) * 100\n",
    "                ax.set_title(f\"{title}\\n{percentage:.2f}%\", fontsize=18)\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            else:\n",
    "                ax.set_title(title, fontsize=18)\n",
    "                ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "\n",
    "    if len(files) < len(axs):\n",
    "        for ax in axs[len(files):]:\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Suptitle con tile e data\n",
    "    fig.suptitle(f\"Tile: {tile} â€” Date: {date.isoformat()}\", fontsize=22)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Report saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TILE 10UED -> 2019 10 06 report_10ued_20191006\n",
    "# TILE 18NWL -> 2019 02 23 report_18nwl_20190109\n",
    "generate_mask_report(\"18NWL\", date(2019, 2, 23), \"report_18nwl_20190223.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_mask_report(\"10UED\", date(2019, 10, 6), \"report_10ued_20191006.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
