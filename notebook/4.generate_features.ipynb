{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory of the current notebook\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "\n",
    "from generate_features import (\n",
    "    get_NDVI,\n",
    "    get_SAVI,\n",
    "    get_NDMI,\n",
    "    get_NDWI,\n",
    "    get_NDBI,\n",
    "    get_NDSI,\n",
    "    get_BSI,\n",
    "    get_sobel,\n",
    "    computeGLCM,\n",
    "    get_NDLI,\n",
    "    get_NDVI705,\n",
    "    get_GNDVI,\n",
    "    get_EVI2,\n",
    "    get_GLI,\n",
    "    get_NDYI)\n",
    "\n",
    "from scripting._process_dems import load_dems, calculate_aspect_from_dems, calculate_slope_from_dems\n",
    "from scripting._process_composites import load_composites\n",
    "\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "def read_yaml(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as yaml_file: return yaml.safe_load(yaml_file)\n",
    "\n",
    "def fix_paths_for_nb(input_dict, old_substring = \"/home/hrlcuser/media\", new_substring = \"/media/datapart/lucazanolo\"):\n",
    "    return {\n",
    "        key: (value.replace(old_substring, new_substring) if isinstance(value, str) else value)\n",
    "        for key, value in input_dict.items()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = fix_paths_for_nb(read_yaml(\"/home/lucazanolo/luca-zanolo/scripts/config_files/4.generate_features.yaml\"))\n",
    "\n",
    "\n",
    "# Output\n",
    "os.makedirs(parameters[\"output_path\"], exist_ok=True)\n",
    "features_date = parameters[\"features_date\"]\n",
    "features_folder_path = f\"{parameters['output_path']}/{str(features_date)[:7]}\"         \n",
    "os.makedirs(features_folder_path, exist_ok=True)\n",
    "\n",
    "SAVE_DATA = False\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load composites, DEMs, slope and aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(os.cpu_count() or 2),\n",
    ") as client:\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "    features_year, features_month = parameters['features_date'].split(\"-\")\n",
    "    if len(features_month) > 1 and features_month[0] == '0':\n",
    "        features_month = features_month[1]\n",
    "\n",
    "    print(\"Loading composites.\")\n",
    "    composites = load_composites(parameters['composites_path'], year=features_year, tile=parameters['tile_id'], month = features_month)\n",
    "\n",
    "    dems = load_dems(parameters['dems_path'],year=parameters['dems_year'], tile=parameters['tile_id'])\n",
    "    slope = calculate_slope_from_dems(dems.band_data)\n",
    "    aspect = calculate_aspect_from_dems(dems.band_data)\n",
    "    \n",
    "    composites = composites.assign({\"dems\":dems.band_data,\n",
    "                        \"slopes\":slope,\n",
    "                        \"aspects\":aspect}).unify_chunks()\n",
    "    \n",
    "    # Fixed GLCM calculation with first month of the year and band 4\n",
    "    band_data = composites.sel(band = parameters['band_to_use'], tile = parameters['tile_id']).band_data.squeeze() # Shape [time, 10980, 10980]\n",
    "    \n",
    "    print(f\"Dems:\\n{dems}\\n\\n\")\n",
    "    print(f\"Aspect:\\n{aspect}\\n\\n\")\n",
    "    print(f\"Slope:\\n{slope}\\n\\n\")\n",
    "    print(f\"Composites:\\n{composites}\\n\\n\")\n",
    "    print(f\"Composites band data:\\n{band_data}\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate GLCM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(os.cpu_count() or 2),\n",
    ") as client:\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "    all_features = []\n",
    "    all_glcms = []\n",
    "\n",
    "    print(f\"Generating GLCM and related features from time: {features_date} ...\")\n",
    "                                        \n",
    "    glcm_features_dict = computeGLCM(band_data.values, parameters['window_size'], parameters['glcm_distance'], parameters['glcm_angle'], parameters['batch_size'])\n",
    "\n",
    "    glcm_features = {\n",
    "        feature_name: xr.DataArray(\n",
    "            glcm_features_dict[feature_name][np.newaxis, :, :],  # Add a new axis for the time dimension\n",
    "            dims=[\"time\", \"y\", \"x\"],\n",
    "            coords={\n",
    "                \"y\": band_data.coords['y'],\n",
    "                \"x\": band_data.coords['x'],\n",
    "                \"time\": band_data.coords['time'],  # Use the time coordinates from the original data\n",
    "                \"spatial_ref\": band_data.spatial_ref,\n",
    "            },\n",
    "            name=feature_name,\n",
    "        ).astype(np.float32)\n",
    "        for feature_name in glcm_features_dict.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving features ...\")   \n",
    "\n",
    "for f_name, f_dt in glcm_features.items():   \n",
    "    \n",
    "    f_path = f\"{features_folder_path}/GLCM{f_name}_{str(features_date)[:7]}.tif\"\n",
    "    print(f\"Saving {f_name} feature to {f_path}\")\n",
    "\n",
    "    if not os.path.exists(f_path):  \n",
    "        f_dt.rio.to_raster(f_path, compress=\"DEFLATE\", num_threads=\"all_cpus\")\n",
    "        print(f\"Features saved at {f_path}\")\n",
    "    else:\n",
    "        print(f\"Features {f_name} at {features_date} already exists. Remove it to recompute.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with dask.distributed.Client(\n",
    "    processes=False,\n",
    "    threads_per_worker=(os.cpu_count() or 2),\n",
    ") as client:\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "    features_funcs = {\n",
    "        \"NDVI\" : get_NDVI,\n",
    "        \"NDVI705\" : get_NDVI705,\n",
    "        \"GNDVI\" : get_GNDVI,\n",
    "        \"NDYI\" : get_NDYI,\n",
    "        \"EVI2\" : get_EVI2,\n",
    "        \"SAVI\" : get_SAVI,\n",
    "        \"NDMI\" : get_NDMI,\n",
    "        \"NDWI\" : get_NDWI,\n",
    "        \"NDBI\" : get_NDBI,\n",
    "        \"NDSI\" : get_NDSI,\n",
    "        \"BSI\" : get_BSI,\n",
    "        \"NDLI\" : get_NDLI,\n",
    "        \"Sobel\" : get_sobel,\n",
    "        \"GLI\" : get_GLI\n",
    "    }\n",
    "    \n",
    "    all_features = {}\n",
    "    all_features_values = {}\n",
    "    composites.band_data.compute()\n",
    "    \n",
    "    for feature_name, feature_func in features_funcs.items():\n",
    "        print(f\"\\nProcessing feature {feature_name}\")\n",
    "        \n",
    "        feature_path = f\"{features_folder_path}/{feature_name}_{str(features_date)[:7]}.tif\"\n",
    "        print(f\"Path: {feature_path}\")\n",
    "\n",
    "        if not os.path.exists(feature_path):\n",
    "            print(\"Computing ...\")\n",
    "            \n",
    "            if feature_name == \"Sobel\":\n",
    "                feature = feature_func(all_features['NDVI'])\n",
    "            else:\n",
    "                feature = feature_func(composites.band_data)\n",
    "            feature.rio.to_raster(feature_path, compress=\"DEFLATE\", num_threads=\"all_cpus\")\n",
    "        else:\n",
    "            print(\"Loading from disk ...\")\n",
    "            feature = rioxarray.open_rasterio(feature_path)\n",
    "        \n",
    "        all_features[feature_name] = feature\n",
    "        all_features_values[feature_name] = feature.values\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite and Features info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show composite bands values info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def band_preparation(band):\n",
    "   return (band / 10000).clip(0,1)\n",
    "\n",
    "for band in composites.band.values:\n",
    "    b = composites.band_data.sel(band = band).values.squeeze()\n",
    "    print(f\"Band {band}:\")\n",
    "    print(f\"Before preparation:\")\n",
    "    print(f\"  Min: {b.min()} | Max: {b.max()}\")\n",
    "    print(f\"  Std: {b.std()} | Mean: {b.mean()} | Var: {b.var()}\")\n",
    "    print(f\"  NaN count: {np.sum(np.isnan(b))}\")\n",
    "    b = band_preparation(b)\n",
    "    print(f\"After preparation:\")\n",
    "    print(f\"  Min: {b.min()} | Max: {b.max()}\")\n",
    "    print(f\"  Std: {b.std()} | Mean: {b.mean()} | Var: {b.var()}\")\n",
    "    print(f\"  NaN count: {np.sum(np.isnan(b))}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, feat in all_features_values.items():\n",
    "    \n",
    "    print(f\"{name} - Mean: {np.mean(feat):.2f} - Std: {np.std(feat):.2f} - {name} - Min: {np.min(feat):.2f} - Max: {np.max(feat):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features with info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, feat in all_features_values.items():\n",
    "    \n",
    "    if name not in ['Sobel']: continue\n",
    "    print(f\"{name} - Mean: {np.mean(feat):.2f} - Std: {np.std(feat):.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(40, 40)) \n",
    "    plt.imshow(feat.squeeze())  # Use an appropriate colormap\n",
    "    plt.colorbar()  # Add colorbar for reference\n",
    "    plt.title(f\"{name} - Mean: {np.mean(feat):.2f} - Std: {np.std(feat):.2f}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extraction_report(parameters, id, save_path=\"features_report.png\", show_plot=True):\n",
    "    \n",
    "    feature_files = [\n",
    "        f\"GLCMASM_{id}.tif\",\n",
    "        f\"GLCMcontrast_{id}.tif\",\n",
    "        f\"GLCMcorrelation_{id}.tif\",\n",
    "        f\"GLCMdissimilarity_{id}.tif\",\n",
    "        f\"GLCMenergy_{id}.tif\",\n",
    "        f\"GLCMhomogeneity_{id}.tif\",\n",
    "        f\"NDVI_{id}.tif\",\n",
    "        f\"NDVI705_{id}.tif\",\n",
    "        f\"GNDVI_{id}.tif\",\n",
    "        f\"NDYI_{id}.tif\",\n",
    "        f\"EVI2_{id}.tif\",\n",
    "        f\"SAVI_{id}.tif\",\n",
    "        f\"NDMI_{id}.tif\",\n",
    "        f\"NDWI_{id}.tif\",\n",
    "        f\"NDBI_{id}.tif\",\n",
    "        f\"NDSI_{id}.tif\",\n",
    "        f\"BSI_{id}.tif\",\n",
    "        f\"NDLI_{id}.tif\",\n",
    "        f\"Sobel_{id}.tif\",\n",
    "        f\"GLI_{id}.tif\"\n",
    "    ]\n",
    "\n",
    "    # Titles for the subplots with new features added\n",
    "    feature_titles = [\n",
    "        \"GLCM ASM\",\n",
    "        \"GLCM Contrast\",\n",
    "        \"GLCM Correlation\",\n",
    "        \"GLCM Dissimilarity\",\n",
    "        \"GLCM Energy\",\n",
    "        \"GLCM Homogeneity\",\n",
    "        \"NDVI\",\n",
    "        \"NDVI705\",\n",
    "        \"GNDVI\",\n",
    "        \"NDYI\",\n",
    "        \"EVI2\",\n",
    "        \"SAVI\",\n",
    "        \"NDMI\",\n",
    "        \"NDWI\",\n",
    "        \"NDBI\",\n",
    "        \"NDSI\",\n",
    "        \"BSI\",\n",
    "        \"NDLI\",\n",
    "        \"Sobel\",\n",
    "        \"GLI\"\n",
    "    ]\n",
    "    \n",
    "    num_features = len(feature_files)\n",
    "    rows = (num_features // 4) + (1 if num_features % 4 != 0 else 0)\n",
    "    fig, axes = plt.subplots(rows, 4, figsize=(20, rows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_file, title) in enumerate(zip(feature_files, feature_titles)):\n",
    "        file_path = os.path.join(parameters['output_path'], report_id, feature_file)\n",
    "        try:\n",
    "            with rasterio.open(file_path) as src:\n",
    "                # Downsample the image to reduce resolution\n",
    "                data = src.read(\n",
    "                    1,\n",
    "                    out_shape=(\n",
    "                        1,\n",
    "                        src.height,\n",
    "                        src.width\n",
    "                    ))\n",
    "                im = axes[i].imshow(data, cmap='viridis')\n",
    "                fig.colorbar(im, ax=axes[i], shrink=0.7)\n",
    "                axes[i].set_title(f\"{title} - Mean: {np.mean(data):.2f} - Std: {np.std(data):.2f}\")\n",
    "                axes[i].axis(\"off\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            axes[i].axis(\"off\")\n",
    "            axes[i].set_title(f\"{title}\\n(Missing)\")\n",
    "\n",
    "    for ax in axes[num_features:]:\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    fig.savefig(save_path)\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Feature extraction report saved at {save_path}\")\n",
    "\n",
    "output_path = parameters[\"output_path\"]\n",
    "report_id = \"2019-01\" # Plot this folder of features\n",
    "features_folder_path = f\"{output_path}/{report_id}\"\n",
    "report_path = f\"{output_path}/reports\"\n",
    "os.makedirs(report_path, exist_ok=True)\n",
    "report_path = f\"{report_path}/{report_id}.png\"\n",
    "\n",
    "\n",
    "create_feature_extraction_report(\n",
    "    parameters=parameters,\n",
    "    id=report_id,\n",
    "    save_path=report_path,\n",
    "    show_plot=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
